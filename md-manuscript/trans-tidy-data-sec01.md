## はじめに

しばしば言われることとして、データ分析の80%がデータのクリーニングと準備の過程に費やされている (Dasu & Johnson 2003)。データの準備は、データ分析で最初の段階として行われるだけではなく、新しい問題が発生したり、新しいデータが収集されたりするたびに、分析の過程で何度も繰り返し行われる必要がある。しかし、費やされる時間が膨大であるにもかかわらず、データをうまくクリーニングする方法についての研究は、驚くほど少ない。難しさの一つに、含まれる作業の範囲の広さがある。作業の範囲は、外れ値の確認から、日付の解析、欠損値の追究に及ぶ。本論文では、この問題に対処するために、データクリーニングにおける小さな、しかし、重要な側面に着目する。それはデータの*整然化* (tidying)であり、分析を容易にするためにデータセットを構造化することを指す。

整然データ(tidy data)の原理はデータセットの内部のデータ値を編成するための標準的手法を提供する。標準があることで、データクリーニングを何もないところから始めたり、車輪の再発明をしたりする必要がなくなるため、最初のデータクリーニングが容易になる。整然データの標準は、データに対する最初の探索と分析を容易にし、効率的に連携するデータ分析ツールの開発を簡単にするように設計されている。現行のツールは、しばしばデータの変換を必要とする。別のツールに入力できるようにするには、あるツールからの出力を変更するための労力を払う必要がある。整然データセットと整然ツールが協調して働くことで、データ分析はより容易になる。すなわち、データの受け渡しというつまらない作業を減らし、興味のある領域の問題に集中することができる。

整然データの原理は、リレーショナルデータベースの原理やコッドのリレーショナル代数 (Codd 1990) の原理と密接に関連している。ただし、整然データの原理は、統計分析者に親しみのある言葉で表現されている。計算機科学者も、データクリーニングの研究に大いに貢献してきた。例えば、Lakshmanan, Sadri & Subramanian (1996) は、雑然データセットを操作できるようにSQLの拡張を定義した。また、Raman and Hellerstein (2001) はデータセットをクリーニングするための枠組みを提供した。Kandel, Paepcke & Hellerstein (2011) は、データクリーニングのためのコードを自動的に生成する親しみやすいユーザーインターフェイスを備えた対話型ツールを開発している。これらのツールは有用であるが、ほとんどの統計分析者にとってなじみのない言語で書かれており、データセットをどのように構造化すべきかの助言をそう多くは提供できておらず、データ分析ツールとのつながりを欠いている。

整然データは、実世界のデータセットに取り組んだ私の経験を通じて開発されてきた。実世界のデータセットは、データの編成に関する制約が（あったとしても）ほとんど課されていないために、しばしば奇怪な方法で構築されている。そのようなデータセットをデータ分析が可能に、そして容易になるように、データが整ったものにすることに、私は非常に長い時間を費やしてきた。さらに、学生が自ら実世界のデータセットに対処できるように、こうしたスキルを学生に伝えることにも取り組んできた。こうした取り組みの過程で、私は `reshape` と `reshape2` (Wickham 2007) というパッケージを開発した。私は直感的にこれらのツールを使い、事例を通じて学生に教えることができたが、私の直感を明文化する枠組みを持っていなかった。本論文はそのための枠組みを提供する。この枠組みは、包括的な「データの哲学」(philosophy of data) を提供する。これは、私のたずさわった `plyr` (Wickham 2011) と `ggplot2` (Wickham 2009) パッケージの根底にあるものである。

本論文は以下のように議論を進める。第2節では、データセットを整然たらしめる3つの特性を定義することから始める。実世界のデータセットのほとんどが整然でないことを踏まえ、第3節では、雑然データセットを整然たらしめるために必要な操作について記述し、さまざまな実例を使って技法を説明する。第4節では、整然データセットを入出力するツールである整然ツールを定義し、どのように整然データと整然ツールが協同してデータ分析を容易にするかについて議論する。これらの原理は、第5節で扱う小規模な事例研究で説明される。最後に、第6節の議論では、この枠組みが見逃していること、追求すれば有益であるかもしれない他のアプローチについてまとめる。
